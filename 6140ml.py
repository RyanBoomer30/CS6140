# -*- coding: utf-8 -*-
"""6140ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wNJbN33Q4Bk0d4jIX0BXUcsnPBgO8OUW
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import MinMaxScaler
import time

SEQ_LEN = 20
BATCH_SIZE = 32
EPOCHS = 50
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


class SequenceDataset(Dataset):
    def __init__(self, X, y, seq_len):
        self.X, self.y = [], []
        for i in range(len(X) - seq_len):
            self.X.append(X[i:i + seq_len])
            self.y.append(y[i + seq_len])
        self.X = np.array(self.X)
        self.y = np.array(self.y)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.float32)

class CustomRNN(nn.Module):
    def __init__(self, input_size=1, hidden_size=64, num_layers=1, dropout=0.0):
        super().__init__()
        self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers,
                          dropout=dropout if num_layers > 1 else 0, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        out, _ = self.rnn(x)
        return self.fc(out[:, -1, :])

class CustomLSTM(nn.Module):
    def __init__(self, input_size=1, hidden_size=64, num_layers=1, dropout=0.0):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers,
                            dropout=dropout if num_layers > 1 else 0, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        out, _ = self.lstm(x)
        return self.fc(out[:, -1, :])


def train_model(model, train_loader, epochs=EPOCHS, lr=0.001, optimizer_type='adam'):
    model = model.to(DEVICE)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr) if optimizer_type == 'adam' \
        else torch.optim.SGD(model.parameters(), lr=lr)

    for epoch in range(epochs):
        model.train()
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)
            optimizer.zero_grad()
            output = model(X_batch).view(-1)
            loss = criterion(output, y_batch)
            loss.backward()
            optimizer.step()
    return model


def evaluate_model(model, X_test_tensor, y_test_tensor):
    model.eval()
    with torch.no_grad():
        X_test_tensor = X_test_tensor.to(DEVICE)
        preds = model(X_test_tensor).view(-1).cpu().numpy()
    y_true = y_test_tensor.numpy()
    return preds, y_true


def plot_predictions(preds, y_true, title="Prediction vs Actual"):
    plt.figure(figsize=(10, 4))
    plt.plot(y_true, label="Actual")
    plt.plot(preds, label="Predicted")
    plt.title(title)
    plt.legend()
    plt.show()


def main():
    csv_path = 'data/tesla_enriched_data.csv'
    df = pd.read_csv(csv_path)
    df.rename(columns={
        "('Date', '')": 'Published',
        "('Close', 'TSLA')": 'Close',
        "('High', 'TSLA')": 'High',
        "('Low', 'TSLA')": 'Low',
        "('Open', 'TSLA')": 'Open',
        "('Volume', 'TSLA')": 'Volume',
    }, inplace=True)
    df_2022_2024 = df[df['Published'] < '2025-01-01']
    df_2025 = df[df['Published'] >= '2025-01-01']

    target_col = df.columns[2]  # Use the column at index 2
    feature_cols = df.columns.drop(['Published', target_col])

    # Scale features
    scaler = MinMaxScaler()
    X_train_scaled = scaler.fit_transform(df_2022_2024[feature_cols])
    y_train_scaled = MinMaxScaler().fit_transform(df_2022_2024['Close'].values.reshape(-1, 1)).flatten()
    X_test_scaled = scaler.transform(df_2025[feature_cols])
    y_test_scaled = MinMaxScaler().fit_transform(df_2025['Close'].values.reshape(-1, 1)).flatten()

    train_dataset = SequenceDataset(X_train_scaled, y_train_scaled, SEQ_LEN)
    test_dataset = SequenceDataset(X_test_scaled, y_test_scaled, SEQ_LEN)

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    X_test_tensor = torch.stack([x[0] for x in test_dataset])
    y_test_tensor = torch.stack([x[1] for x in test_dataset])

    input_size = X_test_tensor.shape[2]

    rnn_configs = [
        {"hidden_size": 32, "num_layers": 1, "dropout": 0.0, "lr": 0.005, "opt": 'adam'},
        {"hidden_size": 64, "num_layers": 2, "dropout": 0.1, "lr": 0.001, "opt": 'adam'},
        {"hidden_size": 128, "num_layers": 2, "dropout": 0.2, "lr": 0.0005, "opt": 'sgd'},
        {"hidden_size": 256, "num_layers": 3, "dropout": 0.3, "lr": 0.0001, "opt": 'adam'},
        {"hidden_size": 64, "num_layers": 1, "dropout": 0.0, "lr": 0.01, "opt": 'sgd'},
    ]

    print("\n--- RNN MODELS ---")
    for i, config in enumerate(rnn_configs):
        print(f"\nTraining RNN Model {i+1} with config: {config}")
        model_params = {k: v for k, v in config.items() if k in ['hidden_size', 'num_layers', 'dropout']}
        rnn_model = CustomRNN(input_size=input_size, **model_params)
        trained = train_model(rnn_model, train_loader, lr=config["lr"], optimizer_type=config["opt"])
        preds, true = evaluate_model(trained, X_test_tensor, y_test_tensor)
        print(f"[RNN {i+1}] MSE: {mean_squared_error(true, preds):.4f}, R^2: {r2_score(true, preds):.4f}")
        plot_predictions(preds, true, f"RNN Model {i+1}")

    lstm_configs = rnn_configs

    print("\n--- LSTM MODELS ---")
    for i, config in enumerate(lstm_configs):
        print(f"\nTraining LSTM Model {i+1} with config: {config}")
        model_params = {k: v for k, v in config.items() if k in ['hidden_size', 'num_layers', 'dropout']}
        lstm_model = CustomLSTM(input_size=input_size, **model_params)
        trained = train_model(lstm_model, train_loader, lr=config["lr"], optimizer_type=config["opt"])
        preds, true = evaluate_model(trained, X_test_tensor, y_test_tensor)
        print(f"[LSTM {i+1}] MSE: {mean_squared_error(true, preds):.4f}, R^2: {r2_score(true, preds):.4f}")
        plot_predictions(preds, true, f"LSTM Model {i+1}")

if __name__ == "__main__":
    main()